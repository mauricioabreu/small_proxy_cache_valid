worker_processes 1;

events {
    use epoll;
    worker_connections 1024;
}

http {
    log_format json_combined escape=json
    '{'
        '"time_local":"$time_local",'
        '"remote_addr":"$remote_addr",'
        '"request":"$request",'
        '"status":$status,'
        '"body_bytes_sent":$body_bytes_sent,'
        '"http_referer":"$http_referer",'
        '"http_user_agent":"$http_user_agent",'
        '"upstream_cache_status":"$upstream_cache_status",'
        '"bucket_time":"$bucket_time",'
        '"request_time":$request_time'
    '}';
    access_log /dev/stdout json_combined;

    proxy_cache_path /var/cache/nginx levels=1:2 keys_zone=small_cache:10m max_size=500m inactive=50m use_temp_path=off;

    upstream backend {
        server 127.0.0.1:8081;
    }

    server {
        listen 8081;

        access_log off;

        location /test {
            return 200 "Small Cache Test";
            add_header Content-Type text/plain;
        }
    }

    server {
        listen 80;

        location / {
            set $cache_time 250;
            set $bucket_time '';

            set_by_lua_block $bucket_time {
                local now = ngx.now();
                local seconds = math.floor(now);
                local milliseconds = math.floor((now - seconds) * 1000);
                local rounded_bucket = math.floor(milliseconds / ngx.var.cache_time) * ngx.var.cache_time;
                if rounded_bucket == 1000 then
                    rounded_bucket = 0;
                    seconds = seconds + 1;
                end

                return string.format("%d.%03d", seconds, rounded_bucket)
            }

            proxy_pass http://backend;
            proxy_cache small_cache;
            proxy_cache_valid 200 302 1s;
            proxy_cache_key $request_uri$bucket_time;
            add_header X-Cache-Status $upstream_cache_status;
            add_header X-Bucket-Time $bucket_time;
        }
    }
}
